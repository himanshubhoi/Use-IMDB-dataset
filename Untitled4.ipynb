{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyypi08hMSrldX61iBnPYW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/himanshubhoi/Use-IMDB-dataset/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "import cv2\n",
        "import random\n",
        "import os\n",
        "from os import listdir\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import label_binarize, LabelBinarizer\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import img_to_array, array_to_img\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Flatten, Dropout, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import model_from_json\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ],
      "metadata": {
        "id": "w3qCvGq-auNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting 12 images to check dataset\n",
        "#Now we will observe some of the iamges that are their in our dataset. We will plot 12 images here using the matplotlib library.\n",
        "plt.figure(figsize=(12,12))\n",
        "path = \"../input/leaf-image-dataset/Plant_images/Potato___Early_blight\"\n",
        "for i in range(1,17): plt.subplot(4,4,i)\n",
        "plt.tight_layout()\n",
        "rand_img = imread(path +'/'+ random.choice(sorted(os.listdir(path))))\n",
        "plt.imshow(rand_img)\n",
        "plt.xlabel(rand_img.shape[1], fontsize = 10)#width of image\n",
        "plt.ylabel(rand_img.shape[0], fontsize = 10)#height of image\n"
      ],
      "metadata": {
        "id": "nR-P_k8ZaToB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting Images to array\n",
        "def convert_image_to_array(image_dir):(tab)\n",
        "try: (tab)(tab)image = cv2.imread(image_dir)\n",
        "(tab)(tab)if image is not None : (tab)(tab)(tab)image = cv2.resize(image, (256,256))\n",
        "(tab)(tab)(tab)#image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "(tab)(tab)(tab)return img_to_array(image)\n",
        "(tab)else : (tab)(tab)return np.array([])\n",
        "(tab)except Exception as e: (tab)(tab)print(f\"Error : {e}\")\n",
        "(tab)(tab)return None"
      ],
      "metadata": {
        "id": "HAE8Jcgub4MH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir = \"../input/leaf-image-dataset/Plant_images\"\n",
        "root_dir = listdir(dir)\n",
        "image_list, label_list = [], []\n",
        "all_labels = ['Corn-Common_rust', 'Potato-Early_blight',␣\n",
        "↪'Tomato-Bacterial_spot']\n",
        "binary_labels = [0,1,2]\n",
        "temp = -1\n",
        "# Reading and converting image to numpy array\n",
        "#Now we will convert all the images into numpy array.\n",
        "for directory in root_dir:\n",
        "(tab)plant_image_list = listdir(f\"{dir}/{directory}\")\n",
        "(tab)temp += 1\n",
        "for files in plant_image_list:\n",
        "(tab)image_path = f\"{dir}/{directory}/{files}\"\n",
        "(tab)image_list.append(convert_image_to_array(image_path))\n",
        "(tab)label_list.append(binary_labels[temp])\n"
      ],
      "metadata": {
        "id": "jCF6B3KOb6j_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the number of classes count\n",
        "label_counts = pd.DataFrame(label_list).value_counts()\n",
        "label_counts.head()\n",
        "#it is a balanced dataset as you can see"
      ],
      "metadata": {
        "id": "uwi9Yx7Db9qX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Next we will observe the shape of the image.\n",
        "image_list[0].shape"
      ],
      "metadata": {
        "id": "-RD1p9WqcAm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the total number of the images which is the length of the labels list.\n",
        "label_list = np.array(label_list)\n",
        "label_list.shape"
      ],
      "metadata": {
        "id": "qCoe0biPcCxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(image_list, label_list,␣\n",
        "↪test_size=0.2, random_state = 10)"
      ],
      "metadata": {
        "id": "6Tc7tfTwcFHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we will normalize the dataset of our images. As pixel values ranges from 0 to 255 so we\n",
        "will divide each image pixel with 255 to normalize the dataset.\n",
        "x_train = np.array(x_train, dtype=np.float16) / 225.0\n",
        "x_test = np.array(x_test, dtype=np.float16) / 225.0\n",
        "x_train = x_train.reshape( -1, 256,256,3)\n",
        "x_test = x_test.reshape( -1, 256,256,3)\n"
      ],
      "metadata": {
        "id": "W2pZClChcFvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "nsDgZYkzcJIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=(256,256,3),␣activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "model.add(Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(8, activation=\"relu\"))\n",
        "model.add(Dense(3, activation=\"softmax\"))\n",
        "model.summary()\n",
        "(SAMPLE OUTPUT)Model: \"sequential\"\n"
      ],
      "metadata": {
        "id": "iZQkmwrOcLnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = Adam(0.\n",
        "↪0001),metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "W395QBrGcYyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Next we will split the dataset into validation and training data.\n",
        "# Splitting the training data set into training and validation data sets\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size =0.2)"
      ],
      "metadata": {
        "id": "twQ3z9WbcbDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "epochs = 50\n",
        "batch_size = 128\n",
        "history = model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs,\n",
        "validation_data = (x_val, y_val))"
      ],
      "metadata": {
        "id": "E5hgsul4cdo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the training history\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(history.history['accuracy'], color='r')\n",
        "plt.plot(history.history['val_accuracy'], color='b')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BFFuws4zcg53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Calculating model accuracy\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {scores[1]*100}\")"
      ],
      "metadata": {
        "id": "AUMd_wNVci_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " y_pred = model.predict(x_test)"
      ],
      "metadata": {
        "id": "zqF3_OKoclVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = array_to_img(x_test[10])\n",
        "img\n"
      ],
      "metadata": {
        "id": "dLxfcK9rcnfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ": # Finding max value from predition list and comaparing original value vs predicted\n",
        "print(\"Originally : \",all_labels[np.argmax(y_test[10])])\n",
        "print(\"Predicted : \",all_labels[np.argmax(y_pred[10])])\n",
        "Originally : Potato-Early_blight\n",
        "Predicted : Potato-Early_blight"
      ],
      "metadata": {
        "id": "djAQrZ0Acq9X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}